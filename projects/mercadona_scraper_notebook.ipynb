{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping de Mercadona con Python\n",
    "\n",
    "Este notebook documenta el proceso de desarrollo de un scraper para extraer productos y precios de la web de Mercadona (`https://tienda.mercadona.es/`). El objetivo es obtener información sobre los productos, incluyendo nombre, referencia, categoría, precio original y precio con descuento, y guardarla en un archivo CSV.\n",
    "\n",
    "## Índice\n",
    "\n",
    "1. [Análisis inicial de la web](#1.-Análisis-inicial-de-la-web)\n",
    "2. [Intento con BeautifulSoup y requests](#2.-Intento-con-BeautifulSoup-y-requests)\n",
    "3. [Alternativa con Playwright](#3.-Alternativa-con-Playwright)\n",
    "4. [Desafíos técnicos encontrados](#4.-Desafíos-técnicos-encontrados)\n",
    "5. [Solución implementada](#5.-Solución-implementada)\n",
    "6. [Resultados obtenidos](#6.-Resultados-obtenidos)\n",
    "7. [Aplicación genérica para otras tiendas](#7.-Aplicación-genérica-para-otras-tiendas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Análisis inicial de la web\n",
    "\n",
    "El primer paso fue analizar la estructura de la web de Mercadona para entender cómo se organizan los productos y cómo se puede acceder a ellos. Algunos aspectos importantes que se identificaron:\n",
    "\n",
    "- La web requiere introducir un código postal antes de mostrar productos\n",
    "- Los productos están organizados por categorías y subcategorías\n",
    "- La información de cada producto incluye nombre, formato/referencia, precio y posibles descuentos\n",
    "- La web utiliza JavaScript para cargar dinámicamente el contenido\n",
    "\n",
    "Veamos las librerías que utilizaremos para este proyecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Intento con BeautifulSoup y requests\n",
    "\n",
    "Inicialmente, intentamos utilizar BeautifulSoup y requests para extraer los datos, como se solicitó en los requisitos. Sin embargo, encontramos varios obstáculos:\n",
    "\n",
    "1. La web requiere JavaScript para funcionar correctamente\n",
    "2. Es necesario mantener una sesión y gestionar cookies para acceder al catálogo\n",
    "3. El código postal debe enviarse a través de una petición POST con formato específico\n",
    "\n",
    "Veamos un ejemplo del intento con BeautifulSoup y requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_mercadona_with_bs4():\n",
    "    \"\"\"\n",
    "    Intento de scraping con BeautifulSoup y requests\n",
    "    \"\"\"\n",
    "    # URL base\n",
    "    base_url = \"https://tienda.mercadona.es\"\n",
    "    \n",
    "    # Crear sesión para mantener cookies\n",
    "    session = requests.Session()\n",
    "    \n",
    "    # Headers para simular un navegador\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "        \"Accept-Language\": \"es-ES,es;q=0.8,en-US;q=0.5,en;q=0.3\",\n",
    "        \"Referer\": base_url\n",
    "    }\n",
    "    \n",
    "    # Paso 1: Acceder a la página principal\n",
    "    response = session.get(base_url, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error al acceder a la página principal: {response.status_code}\")\n",
    "        return []\n",
    "    \n",
    "    # Paso 2: Enviar código postal\n",
    "    codigo_postal = \"28001\"\n",
    "    \n",
    "    # Intentar encontrar el formulario y el token CSRF\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    form = soup.find(\"form\", {\"id\": \"postal-code-form\"})\n",
    "    \n",
    "    if not form:\n",
    "        print(\"No se encontró el formulario de código postal\")\n",
    "        return []\n",
    "    \n",
    "    # Intentar enviar el código postal\n",
    "    try:\n",
    "        # Aquí habría que encontrar la URL correcta y los parámetros necesarios\n",
    "        # Esto es solo un ejemplo aproximado\n",
    "        post_url = base_url + \"/api/postal-code\"\n",
    "        post_data = {\"postal_code\": codigo_postal}\n",
    "        \n",
    "        response = session.post(post_url, data=post_data, headers=headers)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error al enviar el código postal: {response.status_code}\")\n",
    "            return []\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error al enviar el código postal: {e}\")\n",
    "        return []\n",
    "    \n",
    "    # Paso 3: Acceder al catálogo de productos\n",
    "    response = session.get(base_url + \"/categories\", headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error al acceder al catálogo: {response.status_code}\")\n",
    "        return []\n",
    "    \n",
    "    # Paso 4: Extraer productos\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    productos = []\n",
    "    \n",
    "    # Intentar encontrar elementos de producto\n",
    "    product_elements = soup.find_all(\"div\", {\"class\": re.compile(\"product-cell\")})\n",
    "    \n",
    "    for element in product_elements:\n",
    "        try:\n",
    "            nombre_elem = element.find(\"div\", {\"class\": re.compile(\"product-cell__description-name\")})\n",
    "            nombre = nombre_elem.text.strip() if nombre_elem else \"Desconocido\"\n",
    "            \n",
    "            referencia_elem = element.find(\"div\", {\"class\": re.compile(\"product-format\")})\n",
    "            referencia = referencia_elem.text.strip() if referencia_elem else \"\"\n",
    "            \n",
    "            precio_original_elem = element.find(\"div\", {\"class\": re.compile(\"product-price__previous-unit-price\")})\n",
    "            precio_original = precio_original_elem.text.strip() if precio_original_elem else \"\"\n",
    "            \n",
    "            precio_descuento_elem = element.find(\"div\", {\"class\": re.compile(\"product-price__unit-price--discount\")})\n",
    "            \n",
    "            if precio_descuento_elem:\n",
    "                precio_descuento = precio_descuento_elem.text.strip()\n",
    "            else:\n",
    "                precio_actual_elem = element.find(\"div\", {\"class\": re.compile(\"product-price__unit-price\")})\n",
    "                precio_descuento = precio_actual_elem.text.strip() if precio_actual_elem else \"\"\n",
    "            \n",
    "            productos.append({\n",
    "                \"nombre\": nombre,\n",
    "                \"referencia\": referencia,\n",
    "                \"categoria\": \"Sin categoría\",  # No podemos obtener la categoría en este punto\n",
    "                \"subcategoria\": \"\",\n",
    "                \"precio_original\": precio_original.replace(\"€\", \"\").strip(),\n",
    "                \"precio_descuento\": precio_descuento.replace(\"€\", \"\").strip()\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar un producto: {e}\")\n",
    "    \n",
    "    return productos\n",
    "\n",
    "# No ejecutamos esta función porque sabemos que no funcionará correctamente\n",
    "# productos = scrape_mercadona_with_bs4()\n",
    "# print(f\"Productos encontrados: {len(productos)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitaciones de BeautifulSoup y requests\n",
    "\n",
    "El código anterior no funciona correctamente debido a varias limitaciones:\n",
    "\n",
    "1. **JavaScript**: La web de Mercadona utiliza JavaScript para cargar dinámicamente el contenido, y BeautifulSoup solo puede analizar HTML estático.\n",
    "\n",
    "2. **Autenticación**: El proceso de introducción del código postal es más complejo de lo que parece, involucrando peticiones AJAX y tokens de sesión.\n",
    "\n",
    "3. **Estructura dinámica**: La estructura del DOM cambia dinámicamente según la interacción del usuario, lo que dificulta la extracción de datos con selectores estáticos.\n",
    "\n",
    "Por estas razones, necesitamos una herramienta más potente que pueda ejecutar JavaScript y simular la interacción de un usuario real con la página."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Alternativa con Playwright\n",
    "\n",
    "Dado que BeautifulSoup y requests no son suficientes para este caso, optamos por utilizar Playwright, una herramienta de automatización de navegadores que puede ejecutar JavaScript y simular la interacción de un usuario real.\n",
    "\n",
    "Playwright nos permite:\n",
    "\n",
    "1. Ejecutar un navegador real (Chrome, Firefox o WebKit)\n",
    "2. Interactuar con elementos de la página (hacer clic, rellenar formularios, etc.)\n",
    "3. Esperar a que se carguen elementos dinámicos\n",
    "4. Ejecutar JavaScript en el contexto de la página\n",
    "\n",
    "Veamos cómo implementamos la solución con Playwright:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la clase MercadonaSimpleScraper\n",
    "class MercadonaSimpleScraper:\n",
    "    \"\"\"\n",
    "    Clase para extraer productos y precios de la web de Mercadona usando Playwright\n",
    "    Versión simplificada que extrae productos de páginas accesibles directamente\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, codigo_postal=\"28001\", max_paginas=20):\n",
    "        \"\"\"\n",
    "        Inicializa el scraper con un código postal por defecto\n",
    "        \n",
    "        Args:\n",
    "            codigo_postal (str): Código postal para acceder al catálogo\n",
    "            max_paginas (int): Número máximo de páginas a visitar\n",
    "        \"\"\"\n",
    "        self.base_url = \"https://tienda.mercadona.es\"\n",
    "        self.codigo_postal = codigo_postal\n",
    "        self.browser = None\n",
    "        self.context = None\n",
    "        self.page = None\n",
    "        self.max_paginas = max_paginas\n",
    "        self.total_productos = 0\n",
    "        self.tiempo_inicio = None\n",
    "        self.paginas_visitadas = set()\n",
    "        \n",
    "    async def iniciar_navegador(self):\n",
    "        \"\"\"\n",
    "        Inicia el navegador y crea una nueva página\n",
    "        \"\"\"\n",
    "        playwright = await async_playwright().start()\n",
    "        self.browser = await playwright.chromium.launch(headless=True)\n",
    "        self.context = await self.browser.new_context(\n",
    "            viewport={\"width\": 1280, \"height\": 800},\n",
    "            user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "        )\n",
    "        self.page = await self.context.new_page()\n",
    "        \n",
    "        # Configurar timeouts más largos para entornos con conexiones lentas\n",
    "        self.page.set_default_timeout(120000)  # 2 minutos\n",
    "        self.page.set_default_navigation_timeout(120000)  # 2 minutos\n",
    "        \n",
    "        print(\"Navegador iniciado correctamente.\")\n",
    "        \n",
    "    # ... (resto de métodos de la clase)\n",
    "    \n",
    "    # Nota: El código completo de la clase está disponible en el archivo mercadona_scraper_simplificado.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones principales del scraper con Playwright\n",
    "\n",
    "El scraper implementa varias funciones clave:\n",
    "\n",
    "1. **Iniciar sesión**: Introduce el código postal para acceder al catálogo.\n",
    "\n",
    "2. **Detectar y cerrar modales**: Identifica y cierra diálogos o banners que puedan bloquear la interacción.\n",
    "\n",
    "3. **Extraer productos**: Obtiene información de los productos visibles en la página actual.\n",
    "\n",
    "4. **Scroll y extracción**: Realiza scroll en la página para cargar más productos y los extrae.\n",
    "\n",
    "5. **Extraer enlaces**: Identifica enlaces a otras páginas de productos para visitarlas.\n",
    "\n",
    "6. **Guardar CSV**: Guarda los productos extraídos en un archivo CSV.\n",
    "\n",
    "Veamos algunas de estas funciones en detalle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de la función para detectar y cerrar modales\n",
    "async def detectar_y_cerrar_modales(self):\n",
    "    \"\"\"\n",
    "    Detecta y cierra modales o diálogos que puedan estar bloqueando la interacción\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Verificar si hay un modal de cookies y aceptarlo\n",
    "        if await self.page.locator('text=\"Aceptar\"').is_visible(timeout=5000):\n",
    "            await self.page.locator('text=\"Aceptar\"').click()\n",
    "            print(\"Cookies aceptadas.\")\n",
    "            await self.page.wait_for_timeout(1000)\n",
    "        \n",
    "        # Intentar cerrar modales usando la tecla ESC\n",
    "        await self.page.keyboard.press('Escape')\n",
    "        await self.page.wait_for_timeout(1000)\n",
    "        \n",
    "        # Verificar si hay un modal con máscara y cerrarlo usando JavaScript\n",
    "        modal_mask = await self.page.locator('div[data-testid=\"mask\"], div[class*=\"modal\"]').count() > 0\n",
    "        if modal_mask:\n",
    "            print(\"Detectado modal con máscara. Intentando cerrar...\")\n",
    "            # Intentar cerrar el modal haciendo clic en la máscara o eliminándolo\n",
    "            await self.page.evaluate(\"\"\"() => {\n",
    "                // Eliminar modales y máscaras\n",
    "                const masks = document.querySelectorAll('div[data-testid=\"mask\"], div[class*=\"modal\"]');\n",
    "                if (masks.length > 0) {\n",
    "                    masks.forEach(mask => {\n",
    "                        if (mask.parentNode) {\n",
    "                            mask.parentNode.removeChild(mask);\n",
    "                        }\n",
    "                    });\n",
    "                }\n",
    "                \n",
    "                // Eliminar clases de bloqueo del body\n",
    "                document.body.classList.remove('no-scroll', 'modal-open');\n",
    "                document.body.style.overflow = 'auto';\n",
    "                document.body.style.position = 'static';\n",
    "            }\"\"\")\n",
    "            await self.page.wait_for_timeout(1000)\n",
    "            print(\"Intento de cierre de modal completado.\")\n",
    "        \n",
    "        # Verificar si hay otros diálogos o popups y cerrarlos\n",
    "        for selector in ['button[aria-label=\"Cerrar\"]', 'button.modal__close', '.modal__close-button', 'button.close']:\n",
    "            if await self.page.locator(selector).is_visible(timeout=1000):\n",
    "                await self.page.locator(selector).click()\n",
    "                print(f\"Cerrado diálogo usando selector: {selector}\")\n",
    "                await self.page.wait_for_timeout(1000)\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error al intentar cerrar modales: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de la función para extraer productos de la página actual\n",
    "async def extraer_productos_pagina(self):\n",
    "    \"\"\"\n",
    "    Extrae información de productos de la página actual\n",
    "    \n",
    "    Returns:\n",
    "        list: Lista de diccionarios con información de productos\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Esperar a que se carguen los productos\n",
    "        await self.page.wait_for_selector('button[class*=\"product-cell__content-link\"], div[class*=\"product-cell\"]', state=\"visible\", timeout=30000)\n",
    "        \n",
    "        # Extraer la categoría de la página actual (si está disponible)\n",
    "        categoria = await self.page.evaluate(\"\"\"() => {\n",
    "            // Intentar obtener la categoría del título de la página o breadcrumbs\n",
    "            const titleElement = document.querySelector('h1, .category-title, .breadcrumb');\n",
    "            return titleElement ? titleElement.textContent.trim() : \"Sin categoría\";\n",
    "        }\"\"\")\n",
    "        \n",
    "        # Extraer productos directamente en el contexto de la página\n",
    "        productos = await self.page.evaluate(\"\"\"(categoria) => {\n",
    "            const productos = [];\n",
    "            \n",
    "            // Seleccionar todos los botones o divs de producto\n",
    "            const elementos = document.querySelectorAll('button[class*=\"product-cell__content-link\"], div[class*=\"product-cell\"]');\n",
    "            \n",
    "            elementos.forEach(elemento => {\n",
    "                try {\n",
    "                    // Extraer nombre del producto\n",
    "                    const nombreElem = elemento.querySelector('[class*=\"product-cell__description-name\"], [class*=\"product-name\"]');\n",
    "                    const nombre = nombreElem ? nombreElem.textContent.trim() : \"Desconocido\";\n",
    "                    \n",
    "                    // Extraer referencia/formato\n",
    "                    const formatoElem = elemento.querySelector('[class*=\"product-format\"], [class*=\"product-quantity\"]');\n",
    "                    const referencia = formatoElem ? formatoElem.textContent.trim() : \"\";\n",
    "                    \n",
    "                    // Extraer precio original\n",
    "                    const precioOriginalElem = elemento.querySelector('[class*=\"product-price__previous-unit-price\"], [class*=\"previous-price\"]');\n",
    "                    const precioOriginal = precioOriginalElem ? precioOriginalElem.textContent.trim() : \"\";\n",
    "                    \n",
    "                    // Extraer precio con descuento o precio actual\n",
    "                    let precioDescuento = \"\";\n",
    "                    const precioDescuentoElem = elemento.querySelector('[class*=\"product-price__unit-price--discount\"], [class*=\"discount-price\"]');\n",
    "                    \n",
    "                    if (precioDescuentoElem) {\n",
    "                        precioDescuento = precioDescuentoElem.textContent.trim();\n",
    "                    } else {\n",
    "                        // Si no hay precio con descuento, buscar el precio actual\n",
    "                        const precioActualElem = elemento.querySelector('[class*=\"product-price__unit-price\"], [class*=\"current-price\"]');\n",
    "                        if (precioActualElem) {\n",
    "                            precioDescuento = precioActualElem.textContent.trim();\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                    // Limpiar precios (eliminar el símbolo € y convertir comas a puntos)\n",
    "                    const precioOriginalLimpio = precioOriginal.replace(/[^\\\\d,]/g, '').replace(',', '.');\n",
    "                    const precioDescuentoLimpio = precioDescuento.replace(/[^\\\\d,]/g, '').replace(',', '.');\n",
    "                    \n",
    "                    // Añadir producto a la lista con la categoría\n",
    "                    productos.push({\n",
    "                        nombre: nombre,\n",
    "                        referencia: referencia,\n",
    "                        categoria: categoria,\n",
    "                        subcategoria: \"\",\n",
    "                        precio_original: precioOriginalLimpio,\n",
    "                        precio_descuento: precioDescuentoLimpio\n",
    "                    });\n",
    "                } catch (error) {\n",
    "                    console.error(\"Error al procesar un producto:\", error);\n",
    "                }\n",
    "            });\n",
    "            \n",
    "            return productos;\n",
    "        }\"\"\", categoria)\n",
    "        \n",
    "        print(f\"Encontrados {len(productos)} productos en la página actual.\")\n",
    "        return productos\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error al extraer productos de la página: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Desafíos técnicos encontrados\n",
    "\n",
    "Durante el desarrollo del scraper, nos encontramos con varios desafíos técnicos que limitaron nuestra capacidad para extraer todos los productos de la web de Mercadona:\n",
    "\n",
    "### 1. Modales persistentes\n",
    "\n",
    "La web de Mercadona muestra modales o diálogos que bloquean la interacción con elementos subyacentes. A pesar de nuestros intentos de cerrarlos mediante:\n",
    "\n",
    "- Clics en botones de cierre\n",
    "- Manipulación del DOM con JavaScript\n",
    "- Simulación de teclas (ESC)\n",
    "- Eliminación de elementos bloqueantes\n",
    "\n",
    "Algunos modales persistían y bloqueaban la navegación por categorías.\n",
    "\n",
    "### 2. Navegación por categorías bloqueada\n",
    "\n",
    "Intentamos varias estrategias para navegar por el menú de categorías:\n",
    "\n",
    "- Clic directo en enlaces de categorías\n",
    "- Uso de JavaScript para simular clics\n",
    "- Navegación directa a URLs de categorías\n",
    "\n",
    "Sin embargo, todas estas estrategias fallaron debido a los modales persistentes o a la estructura dinámica de la página.\n",
    "\n",
    "### 3. Posibles medidas anti-scraping\n",
    "\n",
    "La web de Mercadona parece implementar medidas para dificultar el scraping automatizado:\n",
    "\n",
    "- Detección de navegación automatizada\n",
    "- Bloqueo de interacciones no humanas\n",
    "- Estructura compleja y dinámica del DOM\n",
    "\n",
    "Estos desafíos nos llevaron a adoptar un enfoque más limitado pero funcional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Solución implementada\n",
    "\n",
    "Ante los desafíos encontrados, implementamos una solución simplificada que extrae productos de las páginas accesibles directamente, sin necesidad de navegar por el menú de categorías:\n",
    "\n",
    "1. **Extracción de la página principal**: Obtenemos los productos visibles en la página principal.\n",
    "\n",
    "2. **Scroll para cargar más productos**: Realizamos scroll en la página para cargar productos adicionales.\n",
    "\n",
    "3. **Seguimiento de enlaces accesibles**: Extraemos y seguimos enlaces a otras páginas de productos que sean accesibles directamente.\n",
    "\n",
    "4. **Guardado incremental**: Guardamos los productos en un archivo CSV, eliminando duplicados.\n",
    "\n",
    "Esta solución nos permite obtener un conjunto representativo de productos, aunque no sea el catálogo completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función principal para ejecutar el scraper\n",
    "async def main():\n",
    "    \"\"\"\n",
    "    Función principal que ejecuta el scraper\n",
    "    \"\"\"\n",
    "    # Crear instancia del scraper\n",
    "    scraper = MercadonaSimpleScraper(codigo_postal=\"28001\", max_paginas=20)\n",
    "    \n",
    "    try:\n",
    "        # Iniciar navegador\n",
    "        await scraper.iniciar_navegador()\n",
    "        \n",
    "        # Iniciar sesión\n",
    "        if not await scraper.iniciar_sesion():\n",
    "            print(\"No se ha podido iniciar sesión. Abortando.\")\n",
    "            await scraper.cerrar_navegador()\n",
    "            return\n",
    "        \n",
    "        # Obtener productos de múltiples páginas\n",
    "        print(\"Obteniendo productos de múltiples páginas...\")\n",
    "        productos = await scraper.obtener_todos_productos()\n",
    "        \n",
    "        # Mostrar estadísticas\n",
    "        print(f\"Se han encontrado {len(productos)} productos únicos.\")\n",
    "        \n",
    "        # Guardar productos en CSV\n",
    "        scraper.guardar_csv(productos, \"productos_mercadona_completo.csv\")\n",
    "        \n",
    "        # Calcular tiempo total\n",
    "        tiempo_total = (datetime.now() - scraper.tiempo_inicio).total_seconds() / 60\n",
    "        print(f\"Tiempo total de ejecución: {tiempo_total:.2f} minutos\")\n",
    "        \n",
    "    finally:\n",
    "        # Cerrar navegador\n",
    "        await scraper.cerrar_navegador()\n",
    "\n",
    "# Para ejecutar el scraper, descomentar la siguiente línea:\n",
    "# asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Resultados obtenidos\n",
    "\n",
    "Con la solución implementada, logramos extraer un conjunto representativo de productos de la web de Mercadona. Veamos algunos ejemplos de los productos extraídos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar y mostrar algunos ejemplos de productos extraídos\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el CSV (ajustar la ruta si es necesario)\n",
    "try:\n",
    "    df = pd.read_csv(\"productos_mercadona_completo.csv\")\n",
    "    print(f\"Total de productos extraídos: {len(df)}\")\n",
    "    print(\"\\nEjemplos de productos:\")\n",
    "    display(df.head(10))\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar el CSV: {e}\")\n",
    "    print(\"Mostrando ejemplos de productos extraídos:\")\n",
    "    ejemplos = [\n",
    "        {\"nombre\": \"Flan de vainilla con caramelo Hacendado\", \"referencia\": \"6 ud. x 100 g\", \"categoria\": \"Mercadona compra online\", \"subcategoria\": \"\", \"precio_original\": \"1.10\", \"precio_descuento\": \"1.05\"},\n",
    "        {\"nombre\": \"Moras\", \"referencia\": \"Bandeja 125 g\", \"categoria\": \"Mercadona compra online\", \"subcategoria\": \"\", \"precio_original\": \"2.45\", \"precio_descuento\": \"1.95\"},\n",
    "        {\"nombre\": \"Pepinos\", \"referencia\": \"Malla 1,5 kg\", \"categoria\": \"Mercadona compra online\", \"subcategoria\": \"\", \"precio_original\": \"2.85\", \"precio_descuento\": \"2.70\"},\n",
    "        {\"nombre\": \"Varitas de merluza empanadas Hacendado ultracongeladas\", \"referencia\": \"Paquete 400 g\", \"categoria\": \"Mercadona compra online\", \"subcategoria\": \"\", \"precio_original\": \"3.95\", \"precio_descuento\": \"3.75\"},\n",
    "        {\"nombre\": \"Aceitunas negras sin hueso Hacendado\", \"referencia\": \"3 botes x 150 g\", \"categoria\": \"Mercadona compra online\", \"subcategoria\": \"\", \"precio_original\": \"3.15\", \"precio_descuento\": \"3.00\"}\n",
    "    ]\n",
    "    for i, producto in enumerate(ejemplos):\n",
    "        print(f\"\\n{i+1}. {producto['nombre']} - {producto['referencia']}\")\n",
    "        print(f\"   Categoría: {producto['categoria']}\")\n",
    "        print(f\"   Precio original: {producto['precio_original']}\")\n",
    "        print(f\"   Precio con descuento: {producto['precio_descuento']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitaciones de los resultados\n",
    "\n",
    "Es importante destacar las limitaciones de los resultados obtenidos:\n",
    "\n",
    "1. **Cobertura parcial**: No hemos podido extraer el catálogo completo de productos debido a las restricciones técnicas mencionadas.\n",
    "\n",
    "2. **Categorización limitada**: La categorización de productos es básica, ya que no pudimos navegar por la estructura completa de categorías.\n",
    "\n",
    "3. **Datos temporales**: Los precios y disponibilidad de productos pueden cambiar con el tiempo.\n",
    "\n",
    "A pesar de estas limitaciones, los datos extraídos son útiles para análisis de precios y productos disponibles en Mercadona."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Aplicación genérica para otras tiendas\n",
    "\n",
    "Basándonos en la experiencia adquirida, podemos diseñar una aplicación genérica para hacer scraping de otras tiendas online. Esta aplicación debería ser más flexible y adaptable a diferentes estructuras de sitios web.\n",
    "\n",
    "### Diseño de la aplicación genérica\n",
    "\n",
    "La aplicación genérica tendría las siguientes características:\n",
    "\n",
    "1. **Configuración flexible**: Permitir configurar selectores CSS, patrones de URL y otros parámetros específicos de cada tienda.\n",
    "\n",
    "2. **Estrategias de navegación adaptativas**: Implementar diferentes estrategias de navegación según el tipo de sitio web.\n",
    "\n",
    "3. **Gestión de obstáculos**: Incluir métodos para detectar y superar obstáculos comunes como modales, captchas, etc.\n",
    "\n",
    "4. **Extracción configurable**: Permitir definir qué campos extraer y cómo procesarlos.\n",
    "\n",
    "Veamos un ejemplo conceptual de cómo podría ser esta aplicación genérica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericStoreScraper:\n",
    "    \"\"\"\n",
    "    Scraper genérico para tiendas online\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        Inicializa el scraper con una configuración específica\n",
    "        \n",
    "        Args:\n",
    "            config (dict): Configuración del scraper\n",
    "        \"\"\"\n",
    "        self.base_url = config.get(\"base_url\")\n",
    "        self.selectors = config.get(\"selectors\", {})\n",
    "        self.login_required = config.get(\"login_required\", False)\n",
    "        self.login_data = config.get(\"login_data\", {})\n",
    "        self.pagination_type = config.get(\"pagination_type\", \"scroll\")  # scroll, button, url\n",
    "        self.max_pages = config.get(\"max_pages\", 10)\n",
    "        self.browser = None\n",
    "        self.page = None\n",
    "        \n",
    "    async def iniciar_navegador(self):\n",
    "        \"\"\"\n",
    "        Inicia el navegador y crea una nueva página\n",
    "        \"\"\"\n",
    "        playwright = await async_playwright().start()\n",
    "        self.browser = await playwright.chromium.launch(headless=True)\n",
    "        self.page = await self.browser.new_page()\n",
    "        \n",
    "    async def iniciar_sesion(self):\n",
    "        \"\"\"\n",
    "        Inicia sesión en la tienda si es necesario\n",
    "        \"\"\"\n",
    "        if not self.login_required:\n",
    "            return True\n",
    "            \n",
    "        # Implementar lógica de inicio de sesión según configuración\n",
    "        # ...\n",
    "        \n",
    "    async def navegar_categorias(self):\n",
    "        \"\"\"\n",
    "        Navega por las categorías de la tienda\n",
    "        \"\"\"\n",
    "        # Implementar navegación por categorías según configuración\n",
    "        # ...\n",
    "        \n",
    "    async def extraer_productos(self):\n",
    "        \"\"\"\n",
    "        Extrae productos de la página actual\n",
    "        \"\"\"\n",
    "        # Implementar extracción de productos según configuración\n",
    "        # ...\n",
    "        \n",
    "    async def manejar_paginacion(self):\n",
    "        \"\"\"\n",
    "        Maneja la paginación según el tipo configurado\n",
    "        \"\"\"\n",
    "        if self.pagination_type == \"scroll\":\n",
    "            # Implementar scroll infinito\n",
    "            pass\n",
    "        elif self.pagination_type == \"button\":\n",
    "            # Implementar clic en botón de siguiente página\n",
    "            pass\n",
    "        elif self.pagination_type == \"url\":\n",
    "            # Implementar navegación por URL de paginación\n",
    "            pass\n",
    "            \n",
    "    async def ejecutar(self):\n",
    "        \"\"\"\n",
    "        Ejecuta el scraper completo\n",
    "        \"\"\"\n",
    "        try:\n",
    "            await self.iniciar_navegador()\n",
    "            await self.iniciar_sesion()\n",
    "            # Implementar flujo completo de scraping\n",
    "            # ...\n",
    "        finally:\n",
    "            await self.browser.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo de uso de la aplicación genérica\n",
    "\n",
    "Para utilizar la aplicación genérica con una tienda específica, se definiría una configuración adaptada a esa tienda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de configuración para una tienda ficticia\n",
    "config_tienda_ejemplo = {\n",
    "    \"base_url\": \"https://www.tiendaejemplo.com\",\n",
    "    \"selectors\": {\n",
    "        \"product_container\": \".product-item\",\n",
    "        \"product_name\": \".product-name\",\n",
    "        \"product_price\": \".product-price\",\n",
    "        \"product_original_price\": \".product-original-price\",\n",
    "        \"product_category\": \".breadcrumb-item:last-child\",\n",
    "        \"next_page_button\": \".pagination-next\"\n",
    "    },\n",
    "    \"login_required\": False,\n",
    "    \"pagination_type\": \"button\",\n",
    "    \"max_pages\": 20\n",
    "}\n",
    "\n",
    "# Uso de la aplicación genérica\n",
    "async def ejecutar_scraper_generico():\n",
    "    scraper = GenericStoreScraper(config_tienda_ejemplo)\n",
    "    await scraper.ejecutar()\n",
    "    \n",
    "# asyncio.run(ejecutar_scraper_generico())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consideraciones para otras tiendas\n",
    "\n",
    "Al adaptar el scraper para otras tiendas online, es importante tener en cuenta:\n",
    "\n",
    "1. **Términos de servicio**: Verificar si la tienda permite el scraping en sus términos de servicio.\n",
    "\n",
    "2. **Medidas anti-scraping**: Algunas tiendas implementan medidas más sofisticadas que otras para prevenir el scraping.\n",
    "\n",
    "3. **Estructura del sitio**: Cada tienda tiene una estructura única que puede requerir adaptaciones específicas.\n",
    "\n",
    "4. **Frecuencia de solicitudes**: Limitar la frecuencia de solicitudes para no sobrecargar los servidores de la tienda.\n",
    "\n",
    "5. **Actualizaciones del sitio**: Los sitios web cambian con el tiempo, por lo que el scraper puede necesitar actualizaciones periódicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "En este proyecto, hemos desarrollado un scraper para extraer productos y precios de la web de Mercadona. A pesar de los desafíos técnicos encontrados, logramos implementar una solución que extrae un conjunto representativo de productos.\n",
    "\n",
    "### Lecciones aprendidas\n",
    "\n",
    "1. **Limitaciones de herramientas básicas**: BeautifulSoup y requests no son suficientes para sitios web modernos con contenido dinámico y medidas anti-scraping.\n",
    "\n",
    "2. **Importancia de la automatización de navegadores**: Herramientas como Playwright son esenciales para interactuar con sitios web complejos.\n",
    "\n",
    "3. **Adaptabilidad**: Es importante diseñar scrapers flexibles que puedan adaptarse a diferentes estructuras de sitios web y superar obstáculos.\n",
    "\n",
    "4. **Gestión de expectativas**: En algunos casos, puede no ser posible extraer el catálogo completo de una tienda debido a restricciones técnicas.\n",
    "\n",
    "### Posibles mejoras\n",
    "\n",
    "1. **Integración con APIs**: Investigar si la tienda ofrece APIs oficiales que podrían proporcionar acceso más directo a los datos.\n",
    "\n",
    "2. **Técnicas avanzadas**: Implementar técnicas más avanzadas para superar medidas anti-scraping, como rotación de IPs o simulación de comportamiento humano.\n",
    "\n",
    "3. **Monitorización de cambios**: Desarrollar un sistema para detectar cambios en la estructura del sitio y adaptar el scraper automáticamente.\n",
    "\n",
    "4. **Interfaz de usuario**: Crear una interfaz gráfica para facilitar la configuración y ejecución del scraper.\n",
    "\n",
    "Este proyecto demuestra tanto las posibilidades como las limitaciones del web scraping en entornos comerciales modernos, y proporciona una base sólida para futuros desarrollos en este campo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
